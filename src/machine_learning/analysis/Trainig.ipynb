{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb+srv://adamstuller:Mit29kis@cluster0-rnyqh.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "db = client.bpdb\n",
    "from bson.code import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_pos_set = set(['D', 'A', 'S'])\n",
    "\n",
    "def only_allowed_pos(x):\n",
    "    try:\n",
    "        return True if x['pos'][0] in allowed_pos_set else False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "filter_allowed_pos lambda comment: list(filter(only_allowed_pos,comment))\n",
    "\n",
    "def concat_words(words):\n",
    "    lemmas = [w['lemma'][0] for w in words]\n",
    "    lemmas = list(filter(lambda x: x!= '?', lemmas))\n",
    "    if len(lemmas) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return \" \".join(lemmas)\n",
    "\n",
    "updated_df = pd.DataFrame([ [concat_words(filter_allowed_pos(x['processed'])), x['class']] for x in db.comments.find()], columns= ['sentence', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test( df ):\n",
    "    x_trains, x_tests,  y_trains, y_tests = [], [], [], []\n",
    "    for tag in df['class'].unique().tolist():\n",
    "        x, y = df[df['class'] == tag].sentence, df[df['class'] == tag]['class']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1000)\n",
    "        x_trains.append(x_train)\n",
    "        x_tests.append(x_test)    \n",
    "        y_trains.append(y_train)    \n",
    "        y_tests.append(y_test)   \n",
    "\n",
    "    return  pd.concat(x_trains), pd.concat(x_tests), pd.concat(y_trains), pd.concat(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "classifier1 = LogisticRegression(solver='lbfgs')\n",
    "classifier2 = GaussianNB()\n",
    "classifier3 = MultinomialNB()\n",
    "classifier4 = SGDClassifier()\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=60,random_state=42)\n",
    "support_vector_machine = svm.SVC(gamma='scale')\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "def transform_comments( df, vectorizer ):\n",
    "    df = df[ ~(df.isnull().sentence == True)].drop_duplicates('sentence')\n",
    "    x_train, x_test, y_train, y_test = get_train_test(df) \n",
    "    vectorizer.fit(x_train)\n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test  = vectorizer.transform(x_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "def train_classifier( x_train, x_test, y_train, y_test, classifier):\n",
    "    classifier.fit(x_train.toarray(), y_train)\n",
    "    return classifier, classifier.score(x_test.toarray(), y_test)\n",
    "\n",
    "def predict( model , messages, vectorizer):\n",
    "    message_series = pd.Series(messages)\n",
    "    return model.predict(vectorizer.transform(message_series))\n",
    "    \n",
    "\n",
    "# model, score = train_classifier( *transform_comments(df, vectorizer), classifier1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, score = train_classifier( *transform_comments(updated_df[updated_df.sentence != ''], vectorizer), random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451388888888888"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>3.063510e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2.634340e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2.260662e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2.034956e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1.725085e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1.724543e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>1.686313e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.346849e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1.175853e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1.173084e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.160039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1.129427e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1.108716e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>9.521822e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>9.389953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>8.853121e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>8.373751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>8.143233e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>8.131557e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>7.929993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>7.736730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>7.461250e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.277868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>7.140586e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>7.019879e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>6.298331e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>6.257619e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>6.012319e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>5.959425e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>5.883258e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.377397e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1.319941e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1.236817e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.127186e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1.106175e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1.103267e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.044444e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1.004315e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>8.222908e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>7.946500e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7.810912e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>7.285466e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>6.706023e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>6.197012e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>5.888740e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>5.516205e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4.594912e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>4.412428e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>3.812478e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3.296288e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>3.292603e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>2.740639e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.470024e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1.954406e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.711650e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>1.675301e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1.460083e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>9.000933e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8.967221e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>6.325643e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance\n",
       "1274  3.063510e-02\n",
       "163   2.634340e-02\n",
       "586   2.260662e-02\n",
       "193   2.034956e-02\n",
       "473   1.725085e-02\n",
       "1532  1.724543e-02\n",
       "809   1.686313e-02\n",
       "371   1.346849e-02\n",
       "596   1.175853e-02\n",
       "620   1.173084e-02\n",
       "930   1.160039e-02\n",
       "487   1.129427e-02\n",
       "882   1.108716e-02\n",
       "447   9.521822e-03\n",
       "1317  9.389953e-03\n",
       "1315  8.853121e-03\n",
       "1387  8.373751e-03\n",
       "1099  8.143233e-03\n",
       "1298  8.131557e-03\n",
       "258   7.929993e-03\n",
       "532   7.736730e-03\n",
       "1346  7.461250e-03\n",
       "111   7.277868e-03\n",
       "728   7.140586e-03\n",
       "1289  7.019879e-03\n",
       "699   6.298331e-03\n",
       "942   6.257619e-03\n",
       "1302  6.012319e-03\n",
       "1383  5.959425e-03\n",
       "1316  5.883258e-03\n",
       "...            ...\n",
       "172   1.377397e-06\n",
       "1269  1.319941e-06\n",
       "1393  1.236817e-06\n",
       "202   1.127186e-06\n",
       "1209  1.106175e-06\n",
       "1567  1.103267e-06\n",
       "188   1.044444e-06\n",
       "540   1.004315e-06\n",
       "1006  8.222908e-07\n",
       "662   7.946500e-07\n",
       "270   7.810912e-07\n",
       "938   7.285466e-07\n",
       "1423  6.706023e-07\n",
       "826   6.197012e-07\n",
       "910   5.888740e-07\n",
       "1561  5.516205e-07\n",
       "599   4.594912e-07\n",
       "1391  4.412428e-07\n",
       "1394  3.812478e-07\n",
       "137   3.296288e-07\n",
       "643   3.292603e-07\n",
       "1538  2.740639e-07\n",
       "197   2.470024e-07\n",
       "617   1.954406e-07\n",
       "35    1.711650e-07\n",
       "926   1.675301e-07\n",
       "428   1.460083e-07\n",
       "208   9.000933e-08\n",
       "200   8.967221e-08\n",
       "281   6.325643e-08\n",
       "\n",
       "[1512 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame(model.feature_importances_, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances[importances['importance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
